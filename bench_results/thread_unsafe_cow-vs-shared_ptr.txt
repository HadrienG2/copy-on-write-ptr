=== MICROBENCHMARK : THREAD-UNSAFE COW POINTER VS RAW SHARED_PTR ===

hadrien@pc-grasland:~/Bureau/Programmation/TestCoW$ g++ -O0 -std=c++11 bench_vs_shared_ptr.cpp -o bench_vs_shared_ptr.bin && ./bench_vs_shared_ptr.bin
[...]

Creating 100000000 pointers from raw pointers
With a raw shared_ptr, this operation takes 9.05853 s
With cow_ptr, it takes 9.70459 s (1.07132x slower)

Creating AND move-constructing 2500000000 pointers
With a raw shared_ptr, this operation takes 285.148 s
With cow_ptr, it takes 404.977 s (1.42023x slower)

Copy-constructing 1000000000 pointers
With a raw shared_ptr, this operation takes 48.1197 s
With cow_ptr, it takes 52.9928 s (1.10127x slower)

Copy-constructing AND move-assigning 5000000000 pointers
With a raw shared_ptr, this operation takes 418.364 s
With cow_ptr, it takes 491.536 s (1.1749x slower)

Copy-assigning 64000000 pointers
With a raw shared_ptr, this operation takes 0.750994 s
With cow_ptr, it takes 1.04189 s (1.38734x slower)

Reading from 5000000000 pointers
With a raw shared_ptr, this operation takes 21.9751 s
With cow_ptr, it takes 35.1145 s (1.59792x slower)

Performing 1920000000 pointer copies AND cold writes
With a raw shared_ptr, this operation takes 26.1059 s
With cow_ptr, it takes 619.9 s (23.7456x slower)

Performing 1920000000 warm pointer writes
With a raw shared_ptr, this operation takes 8.97253 s
With cow_ptr, it takes 21.1923 s (2.36191x slower)


=== RESULTS ANALYSIS ===

When interpreting the results of this test, one should be mindful of three things:
   - The amount of operations is not constant, but optimized per-test to get a measurement uncertainty of a few percents
   - The benchmark is built at -O0 optimization, and may not follow -O3 performance (which cannot be microbenchmarked)
   - Some operations are composite, i.e. made of multiple inner operations that must be separated.

Moves are an example of a composite operation: it is quite hard to build a stateless and lightweight benchmark which
measures the performance of moving a piece of data back and forth between two locations. Instead, what is done is to
measure the overhead of creating + moving a piece of data, then substract the overhead of data creation alone from it.

This is how it is done for move-construction...

   shared_ptr creation takes 90.6ns
   copy_on_write_ptr creation takes 97.0ns
   shared_ptr creation and move-construction takes 114ns
   copy_on_write_ptr creation and move-construction takes 162ns
   
   therefore,
   
   shared_ptr move-construction takes 23ns
   copy_on_write_ptr move-construction takes 65ns
   
   hence the later is 2.8x slower

...and for move-assignment:

   shared_ptr copy-construction takes 48.1ns
   copy_on_write_ptr copy-construction takes 53.0ns
   shared_ptr copy-construction and move-assignment takes 83.7ns
   copy_on_write_ptr copy-construction and move-assignment takes 98.3ns
   
   therefore,
   
   shared_ptr move-assignment takes 35.6ns
   copy_on_write_ptr move-assignment takes 45.3ns
   
   hence the later is 1.3x slower

Finally, by the very nature of the copy-on-write abstraction, cold writes may also only be measured in a composite way:

   shared_ptr copy-assignment takes 11.7ns
   copy_on_write_ptr copy-assignment takes 16.3ns
   shared_ptr copy-assignment and cold write takes 13.6ns
   copy_on_write_ptr copy-assignment and cold write takes 323ns
   
   therefore,
   
   shared_ptr cold write takes 1.9ns
   copy_on_write_ptr cold write takes 307ns
   
   hence the later is 161x slower


=== CONCLUSIONS ===

In terms of elementary operations, before compiler optimization kicks in...
   * Creation from a raw pointer is 1.1x slower
   * Move-constructing is 2.8x slower
   * Copy-constructing is 1.1x slower
   * Moving is 1.3x slower
   * Copying is 1.4x slower
   * Reading is 1.6x slower
   * Cold-writing is 161x slower    => EXPECTED: Dynamic memory allocation overhead.
   * Warm-writing is 2.4x slower

This sets some expectations on how much performance may be expected from thread-safe copy-on-write implementations,
when measured in the same way. It also highlights the well-known fact that for scenarios where writes are infrequent,
copy-on-write of large objects remains quite efficient as a memory usage optimization.
